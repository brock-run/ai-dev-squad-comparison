# Semantic Kernel Environment Variables

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_MODEL_ARCHITECT=codellama:13b
OLLAMA_MODEL_DEVELOPER=codellama:13b
OLLAMA_MODEL_TESTER=llama3.1:8b

# GitHub Configuration
GITHUB_TOKEN=your_github_token_here
GITHUB_REPO=your_repo_name_here
GITHUB_OWNER=your_github_username_here

# General Configuration
TEMPERATURE=0.7
MAX_TOKENS=4000
ENABLE_HUMAN_FEEDBACK=true
CODE_EXECUTION_ALLOWED=true

# Logging
LOG_LEVEL=INFO