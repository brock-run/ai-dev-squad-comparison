# AutoGen Implementation Environment Variables

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_ARCHITECT=llama3.1:8b
OLLAMA_MODEL_DEVELOPER=codellama:13b
OLLAMA_MODEL_TESTER=llama3.1:8b

# GitHub Configuration
GITHUB_API_TOKEN=your_github_token_here
GITHUB_USERNAME=your_github_username
GITHUB_REPO=your_repository_name

# AutoGen Settings
AUTOGEN_USE_DOCKER=false
AUTOGEN_CACHE_DIR=./cache
ENABLE_HUMAN_FEEDBACK=true
CODE_EXECUTION_ALLOWED=true

# Model Configuration
MAX_TOKENS=4096
TEMPERATURE=0.7

# Logging
LOG_LEVEL=INFO