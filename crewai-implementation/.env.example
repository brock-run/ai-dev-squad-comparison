# CrewAI Implementation Environment Variables

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL_ARCHITECT=llama3.1:8b
OLLAMA_MODEL_DEVELOPER=codellama:13b
OLLAMA_MODEL_TESTER=llama3.1:8b

# GitHub Configuration
GITHUB_API_TOKEN=your_github_token_here
GITHUB_USERNAME=your_github_username
GITHUB_REPO=your_repository_name

# CrewAI Settings
CREWAI_VERBOSE=true
ENABLE_HUMAN_FEEDBACK=true
MAX_TOKENS_PER_CALL=4096
TEMPERATURE=0.7

# Logging
LOG_LEVEL=INFO